import { useState, useCallback, useRef, useEffect } from 'react';
import { toast } from 'sonner';
import { AudioFile } from '@/components/AudioTrack';

export const useAudioManager = () => {
  const [voiceFiles, setVoiceFiles] = useState<AudioFile[]>([]);
  const [musicFiles, setMusicFiles] = useState<AudioFile[]>([]);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [voiceVolume, setVoiceVolume] = useState(70);
  const [musicVolume, setMusicVolume] = useState(30);
  const [voiceMuted, setVoiceMuted] = useState(false);
  const [musicMuted, setMusicMuted] = useState(false);
  const [composedAudioUrl, setComposedAudioUrl] = useState<string | null>(null);
  const [isComposing, setIsComposing] = useState(false);
  
  // æ–°å¢çš„éŸ³é¢‘å¢å¼ºæ§åˆ¶çŠ¶æ€
  const [voiceGain, setVoiceGain] = useState(100);
  const [musicGain, setMusicGain] = useState(100);
  const [voicePitch, setVoicePitch] = useState(100);
  const [voiceFileGains, setVoiceFileGains] = useState<Record<string, number>>({});
  const [isNormalizingVolume, setIsNormalizingVolume] = useState(false);

  // éŸ³é¢‘ä¸Šä¸‹æ–‡å’ŒæºèŠ‚ç‚¹å¼•ç”¨
  const audioContextRef = useRef<AudioContext | null>(null);
  const voiceSourcesRef = useRef<AudioBufferSourceNode[]>([]);
  const musicSourcesRef = useRef<AudioBufferSourceNode[]>([]);
  const startTimeRef = useRef<number>(0);
  const animationFrameRef = useRef<number>();
  const activeUrlsRef = useRef<Set<string>>(new Set()); // è·Ÿè¸ªæ‰€æœ‰æ´»è·ƒçš„blob URL
  const urlRefCountRef = useRef<Map<string, number>>(new Map()); // URLå¼•ç”¨è®¡æ•°
  // æ¯è½¨é“ä¸»å¢ç›ŠèŠ‚ç‚¹å¼•ç”¨ï¼Œæ”¯æŒæ’­æ”¾ä¸­å®æ—¶è°ƒèŠ‚éŸ³é‡/å¢ç›Š/é™éŸ³
  const voiceMasterGainRef = useRef<GainNode | null>(null);
  const musicMasterGainRef = useRef<GainNode | null>(null);

  // è°ƒè¯•å‡½æ•°ï¼šè®°å½•å½“å‰æ´»è·ƒçš„URL
  const logActiveUrls = useCallback(() => {
    if (activeUrlsRef.current.size > 0) {
      console.log('ğŸ”— å½“å‰æ´»è·ƒçš„blob URLs:', Array.from(activeUrlsRef.current));
      console.log('ğŸ“Š URLå¼•ç”¨è®¡æ•°:', Object.fromEntries(urlRefCountRef.current));
    }
  }, []);

  // æ·»åŠ URLå¼•ç”¨
  const addUrlRef = useCallback((url: string) => {
    const currentCount = urlRefCountRef.current.get(url) || 0;
    urlRefCountRef.current.set(url, currentCount + 1);
    activeUrlsRef.current.add(url);
  }, []);

  const removeUrlRef = useCallback((url: string) => {
    const currentCount = urlRefCountRef.current.get(url) || 0;
    if (currentCount <= 1) {
      urlRefCountRef.current.delete(url);
      activeUrlsRef.current.delete(url);
      try {
        URL.revokeObjectURL(url);
        console.log('ğŸ—‘ï¸ å·²é‡Šæ”¾blob URL:', url);
      } catch (error) {
        console.warn('é‡Šæ”¾URLæ—¶å‡ºé”™:', error);
      }
    } else {
      urlRefCountRef.current.set(url, currentCount - 1);
    }
  }, []);

  // éªŒè¯blob URLæ˜¯å¦æœ‰æ•ˆ
  const validateBlobUrl = useCallback((url: string): boolean => {
    try {
      // æ£€æŸ¥URLæ ¼å¼
      if (!url || !url.startsWith('blob:')) {
        return false;
      }
      
      // æ£€æŸ¥æ˜¯å¦åœ¨æ´»è·ƒURLé›†åˆä¸­
      return activeUrlsRef.current.has(url);
    } catch (error) {
      console.warn('éªŒè¯blob URLæ—¶å‡ºé”™:', error);
      return false;
    }
  }, []);

  // è‡ªåŠ¨æ¢å¤å¤±æ•ˆçš„URL
  const recoverFailedUrl = useCallback(async (audioFile: AudioFile): Promise<string | null> => {
    try {
      if (!audioFile.file) {
        console.warn('âš ï¸ æ— æ³•æ¢å¤URLï¼šåŸå§‹æ–‡ä»¶å¯¹è±¡ä¸å­˜åœ¨');
        return null;
      }

      console.log('ğŸ”„ å°è¯•æ¢å¤å¤±æ•ˆçš„URL:', audioFile.name);
      
      // ç§»é™¤æ—§çš„URLå¼•ç”¨
      if (audioFile.url) {
        removeUrlRef(audioFile.url);
      }
      
      // åˆ›å»ºæ–°çš„blob URL
      const newUrl = URL.createObjectURL(audioFile.file);
      addUrlRef(newUrl);
      
      // éªŒè¯æ–°URLæ˜¯å¦å¯ç”¨
      return new Promise((resolve) => {
        const testAudio = new Audio();
        
        const cleanup = () => {
          testAudio.removeEventListener('loadedmetadata', onSuccess);
          testAudio.removeEventListener('error', onError);
        };
        
        const onSuccess = () => {
          cleanup();
          console.log('âœ… URLæ¢å¤æˆåŠŸ:', newUrl);
          resolve(newUrl);
        };
        
        const onError = () => {
          cleanup();
          removeUrlRef(newUrl);
          console.warn('âŒ URLæ¢å¤å¤±è´¥');
          resolve(null);
        };
        
        testAudio.addEventListener('loadedmetadata', onSuccess);
        testAudio.addEventListener('error', onError);
        testAudio.src = newUrl;
        testAudio.load();
        
        // 5ç§’è¶…æ—¶
        setTimeout(() => {
          cleanup();
          removeUrlRef(newUrl);
          resolve(null);
        }, 5000);
      });
    } catch (error) {
      console.error('æ¢å¤URLæ—¶å‡ºé”™:', error);
      return null;
    }
  }, [addUrlRef, removeUrlRef]);

  // æ£€æŸ¥å¹¶è‡ªåŠ¨æ¢å¤å¤±æ•ˆçš„éŸ³é¢‘æ–‡ä»¶
  const checkAndRecoverAudioFiles = useCallback(async () => {
    const checkFiles = async (files: AudioFile[], setFiles: React.Dispatch<React.SetStateAction<AudioFile[]>>) => {
      const updatedFiles = await Promise.all(
        files.map(async (file) => {
          if (!validateBlobUrl(file.url)) {
            console.log('ğŸ” æ£€æµ‹åˆ°å¤±æ•ˆURLï¼Œå°è¯•è‡ªåŠ¨æ¢å¤:', file.name);
            const recoveredUrl = await recoverFailedUrl(file);
            
            if (recoveredUrl) {
              return { ...file, url: recoveredUrl };
            } else {
              // æ¢å¤å¤±è´¥ï¼Œæ˜¾ç¤ºå‹å¥½æç¤º
              toast.error(
                `éŸ³é¢‘æ–‡ä»¶ "${file.name}" å·²å¤±æ•ˆï¼Œè¯·é‡æ–°ä¸Šä¼ æˆ–åˆ·æ–°é¡µé¢åé‡æ–°é€‰æ‹©éŸ³é¢‘æ–‡ä»¶`,
                {
                  duration: 5000,
                  action: {
                    label: 'äº†è§£æ›´å¤š',
                    onClick: () => {
                      toast.info(
                        'éŸ³é¢‘æ–‡ä»¶å¤±æ•ˆé€šå¸¸å‘ç”Ÿåœ¨é¡µé¢åˆ·æ–°æˆ–é•¿æ—¶é—´æœªä½¿ç”¨åã€‚é‡æ–°ä¸Šä¼ æ–‡ä»¶å³å¯è§£å†³æ­¤é—®é¢˜ã€‚',
                        { duration: 8000 }
                      );
                    }
                  }
                }
              );
              return file; // ä¿ç•™åŸæ–‡ä»¶ï¼Œè®©ç”¨æˆ·å†³å®šæ˜¯å¦åˆ é™¤
            }
          }
          return file;
        })
      );
      
      // åªæœ‰åœ¨æœ‰å˜åŒ–æ—¶æ‰æ›´æ–°çŠ¶æ€
      const hasChanges = updatedFiles.some((file, index) => file.url !== files[index].url);
      if (hasChanges) {
        setFiles(updatedFiles);
      }
    };

    await Promise.all([
      checkFiles(voiceFiles, setVoiceFiles),
      checkFiles(musicFiles, setMusicFiles)
    ]);
  }, [voiceFiles, musicFiles, validateBlobUrl, recoverFailedUrl]);

  // æ¸…ç†æ‰€æœ‰URLå¼•ç”¨
  const cleanupAllUrls = useCallback(() => {
    // å¼€å‘æ¨¡å¼ä¸‹è·³è¿‡URLæ¸…ç†ï¼Œé¿å…HMRæ—¶æ–‡ä»¶å¤±æ•ˆ
  // @ts-ignore
  if ((import.meta as any).env?.DEV && (import.meta as any).hot) {
      console.log('ğŸ”§ å¼€å‘æ¨¡å¼ï¼šè·³è¿‡URLæ¸…ç†ä»¥æ”¯æŒçƒ­é‡è½½');
      return;
    }
    
    console.log('ğŸ§¹ å¼€å§‹æ¸…ç†æ‰€æœ‰blob URLs...');
    const urls = Array.from(activeUrlsRef.current);
    urls.forEach(url => {
      try {
        URL.revokeObjectURL(url);
        console.log('ğŸ—‘ï¸ å·²é‡Šæ”¾blob URL:', url);
      } catch (error) {
        console.warn('é‡Šæ”¾URLæ—¶å‡ºé”™:', error);
      }
    });
    activeUrlsRef.current.clear();
    urlRefCountRef.current.clear();
    console.log('âœ… æ‰€æœ‰blob URLså·²æ¸…ç†å®Œæˆ');
  }, []);

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      cleanupAllUrls();
    };
  }, [cleanupAllUrls]);

  // å¼€å‘æ¨¡å¼ä¸‹çš„HMRæ”¯æŒ
  useEffect(() => {
  // @ts-ignore
  if ((import.meta as any).env?.DEV && (import.meta as any).hot) {
      // HMRæ—¶è‡ªåŠ¨æ£€æŸ¥å¹¶æ¢å¤éŸ³é¢‘æ–‡ä»¶
      const handleHMR = () => {
        console.log('ğŸ”¥ æ£€æµ‹åˆ°çƒ­é‡è½½ï¼Œæ£€æŸ¥éŸ³é¢‘æ–‡ä»¶çŠ¶æ€...');
        setTimeout(() => {
          checkAndRecoverAudioFiles();
        }, 1000); // å»¶è¿Ÿ1ç§’ç¡®ä¿ç»„ä»¶å®Œå…¨é‡æ–°æ¸²æŸ“
      };

  // @ts-ignore
  (import.meta as any).hot.on('vite:beforeUpdate', handleHMR);
      
      return () => {
  // @ts-ignore
  (import.meta as any).hot?.off('vite:beforeUpdate', handleHMR);
      };
    }
  }, [checkAndRecoverAudioFiles]);

  // å®šæœŸæ£€æŸ¥éŸ³é¢‘æ–‡ä»¶çŠ¶æ€ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
  useEffect(() => {
  // @ts-ignore
  if (!(import.meta as any).env?.DEV) {
      const interval = setInterval(() => {
        checkAndRecoverAudioFiles();
      }, 30000); // æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡

      return () => clearInterval(interval);
    }
  }, [checkAndRecoverAudioFiles]);

  const initAudioContext = useCallback(async () => {
    if (!audioContextRef.current) {
      try {
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
        
        if (audioContextRef.current.state === 'suspended') {
          await audioContextRef.current.resume();
        }
        
        console.log('ğŸµ éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–æˆåŠŸ');
      } catch (error) {
        console.error('âŒ éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–å¤±è´¥:', error);
        throw error;
      }
    }
    return audioContextRef.current;
  }, []);

  const createAudioFile = useCallback(async (file: File): Promise<AudioFile> => {
    console.log('ğŸ“ å¼€å§‹å¤„ç†æ–‡ä»¶:', file.name);
    
    let timeoutId: NodeJS.Timeout;
    
    return new Promise(async (resolve, reject) => {
      try {
        // åˆ›å»ºblob URLå¹¶æ·»åŠ å¼•ç”¨
        const url = URL.createObjectURL(file);
        addUrlRef(url);
        console.log('ğŸ”— åˆ›å»ºblob URL:', url);
        
        // éªŒè¯URL
        if (!validateBlobUrl(url)) {
          throw new Error('åˆ›å»ºçš„blob URLæ— æ•ˆ');
        }
        
        const setupAudioLoading = () => {
          const audio = new Audio();
          let isResolved = false;
          
          const handleError = (error: any) => {
            if (isResolved) return;
            
            console.warn('âš ï¸ éŸ³é¢‘åŠ è½½å‡ºé”™ï¼Œå°è¯•æ¢å¤:', error);
            
            // å¦‚æœURLåŠ è½½å¤±è´¥ï¼Œå°è¯•é‡æ–°åˆ›å»º
            if (!validateBlobUrl(url)) {
              console.log('ğŸ”„ URLå·²å¤±æ•ˆï¼Œé‡æ–°åˆ›å»º...');
              const newUrl = URL.createObjectURL(file);
              addUrlRef(newUrl);
              
              // é‡æ–°åˆ›å»ºAudioå¯¹è±¡å¹¶è®¾ç½®äº‹ä»¶ç›‘å¬
              const newAudio = new Audio();
              newAudio.addEventListener('loadedmetadata', () => {
                if (isResolved) return;
                isResolved = true;
                clearTimeout(timeoutId);
                
                const audioFile: AudioFile = {
                  id: Date.now().toString(),
                  name: file.name,
                  url: newUrl,
                  duration: newAudio.duration || 0,
                  file: file
                };
                
                console.log('âœ… éŸ³é¢‘æ–‡ä»¶åˆ›å»ºæˆåŠŸ (æ¢å¤):', audioFile);
                resolve(audioFile);
              });
              
              newAudio.addEventListener('error', () => {
                if (isResolved) return;
                isResolved = true;
                clearTimeout(timeoutId);
                removeUrlRef(newUrl);
                reject(new Error(`æ— æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶: ${file.name}`));
              });
              
              newAudio.src = newUrl;
              newAudio.load();
            } else {
              isResolved = true;
              clearTimeout(timeoutId);
              removeUrlRef(url);
              reject(error);
            }
          };
          
          // éŸ³é¢‘å…ƒæ•°æ®åŠ è½½å®Œæˆ
          audio.addEventListener('loadedmetadata', async () => {
            if (isResolved) return;
            clearTimeout(timeoutId);

            const finalize = (finalDuration: number) => {
              if (isResolved) return;
              isResolved = true;
              const audioFile: AudioFile = {
                id: Date.now().toString(),
                name: file.name,
                url: url,
                duration: finalDuration || 0,
                file: file
              };
              console.log('âœ… éŸ³é¢‘æ–‡ä»¶åˆ›å»ºæˆåŠŸ:', audioFile);
              resolve(audioFile);
            };

            let duration = audio.duration || 0;
            // å¤„ç†éƒ¨åˆ†å½•éŸ³ï¼ˆå¦‚ webmï¼‰å‡ºç° duration ä¸º 0 æˆ– Infinity çš„æƒ…å†µ
            if (!isFinite(duration) || duration === 0) {
              try {
                const arrayBuffer = await file.arrayBuffer();
                const Ctx = (window as any).AudioContext || (window as any).webkitAudioContext;
                if (Ctx) {
                  const ctx = new Ctx();
                  const audioBuffer = await ctx.decodeAudioData(arrayBuffer);
                  duration = audioBuffer.duration;
                  ctx.close?.();
                }
              } catch (e) {
                console.warn('ä½¿ç”¨ AudioContext è§£ç æ—¶é•¿å¤±è´¥ï¼Œå°†å°è¯• timeupdate å›é€€', e);
              }
            }

            if (!isFinite(duration) || duration === 0) {
              const onTimeUpdate = () => {
                if (!isResolved && isFinite(audio.duration) && audio.duration > 0) {
                  audio.removeEventListener('timeupdate', onTimeUpdate);
                  finalize(audio.duration);
                }
              };
              audio.addEventListener('timeupdate', onTimeUpdate);
              try { audio.currentTime = 1e101; } catch {}
            } else {
              finalize(duration);
            }
          });
          
          // éŸ³é¢‘å¯ä»¥æ’­æ”¾
          audio.addEventListener('canplaythrough', () => {
            console.log('ğŸµ éŸ³é¢‘å¯ä»¥æ’­æ”¾:', file.name);
          });
          
          // éŸ³é¢‘åŠ è½½é”™è¯¯
          audio.addEventListener('error', (e) => {
            handleError(e);
          });
          
          // è®¾ç½®è¶…æ—¶
          timeoutId = setTimeout(() => {
            if (!isResolved) {
              handleError(new Error('éŸ³é¢‘åŠ è½½è¶…æ—¶'));
            }
          }, 10000);
          
          // å¼€å§‹åŠ è½½
          audio.preload = 'metadata';
          audio.src = url;
          audio.load();
        };
        
        try {
          setupAudioLoading();
        } catch (error) {
          console.error('âŒ éŸ³é¢‘åŠ è½½åˆå§‹åŒ–å¤±è´¥:', error);
          removeUrlRef(url);
          reject(error);
        }
        
      } catch (error) {
        console.error('âŒ åˆ›å»ºéŸ³é¢‘æ–‡ä»¶å¤±è´¥:', error);
        reject(error);
      } finally {
        // æ¸…ç†è¶…æ—¶
        if (timeoutId) {
          clearTimeout(timeoutId);
        }
      }
    });
  }, [addUrlRef, validateBlobUrl, logActiveUrls]);

  const handleFilesUpload = useCallback(async (files: File[], type: 'voice' | 'music') => {
    console.log(`å¼€å§‹å¤„ç†${type}æ–‡ä»¶ä¸Šä¼ :`, files.map(f => f.name));
    if (!files || files.length === 0) {
      toast.error('æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶');
      return;
    }
    const successfulFiles: AudioFile[] = [];
    const failedFiles: string[] = [];
    for (const file of files) {
      try {
        console.log(`æ­£åœ¨å¤„ç†æ–‡ä»¶: ${file.name}`);
        const audioFile = await createAudioFile(file);
        successfulFiles.push(audioFile);
        console.log(`âœ… æ–‡ä»¶å¤„ç†æˆåŠŸ: ${file.name}`);
      } catch (error: any) {
        let reason = 'æœªçŸ¥é”™è¯¯';
        if (error instanceof Error) {
          reason = error.message;
        } else if (typeof error === 'string') {
          reason = error;
        }
        console.error(`âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: ${file.name}`, reason);
        toast.error(`æ–‡ä»¶ ${file.name} ä¸Šä¼ å¤±è´¥: ${reason}`);
        failedFiles.push(file.name);
      }
    }
    if (successfulFiles.length > 0) {
      if (type === 'voice') {
        setVoiceFiles(prev => [...prev, ...successfulFiles]);
      } else {
        setMusicFiles(prev => [...prev, ...successfulFiles]);
      }
      toast.success(`æˆåŠŸæ·»åŠ  ${successfulFiles.length} ä¸ª${type === 'voice' ? 'è¯­éŸ³' : 'éŸ³ä¹'}æ–‡ä»¶`);
    }
    if (failedFiles.length > 0) {
      toast.error(
        `${failedFiles.length} ä¸ªæ–‡ä»¶ä¸Šä¼ å¤±è´¥: ${failedFiles.join(', ')}`,
        {
          duration: 6000,
          action: {
            label: 'é‡è¯•',
            onClick: () => {
              toast.info('è¯·é‡æ–°é€‰æ‹©å¤±è´¥çš„æ–‡ä»¶è¿›è¡Œä¸Šä¼ ');
            }
          }
        }
      );
    }
    if (successfulFiles.length === 0 && failedFiles.length > 0) {
      toast.error('æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€å¤§å°ï¼ˆå°äº100MBï¼‰ã€æµè§ˆå™¨å…¼å®¹æ€§æˆ–åˆ·æ–°é¡µé¢é‡è¯•');
    }
  }, [createAudioFile]);

  const removeFile = useCallback((id: string, type: 'voice' | 'music') => {
    if (type === 'voice') {
      setVoiceFiles(prev => {
        const fileToRemove = prev.find(f => f.id === id);
        if (fileToRemove?.url) {
          removeUrlRef(fileToRemove.url);
        }
        return prev.filter(f => f.id !== id);
      });
    } else {
      setMusicFiles(prev => {
        const fileToRemove = prev.find(f => f.id === id);
        if (fileToRemove?.url) {
          removeUrlRef(fileToRemove.url);
        }
        return prev.filter(f => f.id !== id);
      });
    }
  }, [removeUrlRef]);

  // é‡æ–°æ’åºæ–‡ä»¶ï¼ˆæ”¯æŒè¯­éŸ³/éŸ³ä¹è½¨é“ï¼‰
  const reorderFiles = useCallback((startIndex: number, endIndex: number, type: 'voice' | 'music') => {
    try {
      const move = (list: AudioFile[]) => {
        if (startIndex === endIndex) return list;
        if (startIndex < 0 || endIndex < 0 || startIndex >= list.length || endIndex >= list.length) {
          console.warn('reorderFiles: ç´¢å¼•è¶Šç•Œ', { startIndex, endIndex, length: list.length });
          return list;
        }
        const next = list.slice();
        const [moved] = next.splice(startIndex, 1);
        next.splice(endIndex, 0, moved);
        return next;
      };

      if (type === 'voice') {
        setVoiceFiles(prev => move(prev));
      } else {
        setMusicFiles(prev => move(prev));
      }
    } catch (error) {
      console.error('é‡æ–°æ’åºå¤±è´¥:', error);
      toast.error('é‡æ–°æ’åºå¤±è´¥');
    }
  }, []);

  const clearAllFiles = useCallback(() => {
    // æ¸…ç†æ‰€æœ‰æ–‡ä»¶çš„URLå¼•ç”¨
    [...voiceFiles, ...musicFiles].forEach(file => {
      if (file.url) {
        removeUrlRef(file.url);
      }
    });
    
    setVoiceFiles([]);
    setMusicFiles([]);
    setComposedAudioUrl(null);
    toast.success('å·²æ¸…ç©ºæ‰€æœ‰æ–‡ä»¶');
  }, [voiceFiles, musicFiles, removeUrlRef]);

  const stopPlayback = useCallback(() => {
    // åœæ­¢æ‰€æœ‰éŸ³é¢‘æº
    voiceSourcesRef.current.forEach(source => {
      try {
        source.stop();
        source.disconnect();
      } catch (error) {
        // å¿½ç•¥å·²ç»åœæ­¢çš„æºçš„é”™è¯¯
      }
    });
    
    musicSourcesRef.current.forEach(source => {
      try {
        source.stop();
        source.disconnect();
      } catch (error) {
        // å¿½ç•¥å·²ç»åœæ­¢çš„æºçš„é”™è¯¯
      }
    });
    
    // æ¸…ç©ºæºæ•°ç»„
    voiceSourcesRef.current = [];
    musicSourcesRef.current = [];

    // æ–­å¼€å¹¶æ¸…ç©ºä¸»å¢ç›ŠèŠ‚ç‚¹
    try { voiceMasterGainRef.current?.disconnect(); } catch {}
    try { musicMasterGainRef.current?.disconnect(); } catch {}
    voiceMasterGainRef.current = null;
    musicMasterGainRef.current = null;
    
    // å–æ¶ˆåŠ¨ç”»å¸§
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }
    
    setIsPlaying(false);
    setCurrentTime(0);
    startTimeRef.current = 0;
  }, []);

  const playAudio = useCallback(async () => {
    try {
      const audioContext = await initAudioContext();
      stopPlayback();
      if (voiceFiles.length === 0 && musicFiles.length === 0) {
        toast.error('è¯·å…ˆæ·»åŠ éŸ³é¢‘æ–‡ä»¶');
        return;
      }
      // è®¾ç½®æ’­æ”¾èµ·å§‹æ—¶é—´ç”¨äºè¿›åº¦æ›´æ–°
      startTimeRef.current = audioContext.currentTime;
      // 1. è¯­éŸ³è½¨é“é¡ºåºæ‹¼æ¥
      let voiceDuration = 0;
      const voiceBufferList: { buffer: AudioBuffer; gain: number; duration: number }[] = [];
      for (const file of voiceFiles) {
        try {
          const response = await fetch(file.url);
          const arrayBuffer = await response.arrayBuffer();
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          const individualGain = voiceFileGains[file.id] || 100;
          // å•æ–‡ä»¶å¢ç›Šä»…ä¿ç•™æ–‡ä»¶çº§å·®å¼‚ï¼Œè½¨é“çº§éŸ³é‡/å¢ç›Š/é™éŸ³ç”±ä¸»å¢ç›ŠèŠ‚ç‚¹ç»Ÿä¸€æ§åˆ¶
          voiceBufferList.push({
            buffer: audioBuffer,
            gain: (individualGain / 100),
            duration: audioBuffer.duration
          });
          voiceDuration += audioBuffer.duration;
        } catch (error) {
          console.error(`åŠ è½½è¯­éŸ³æ–‡ä»¶å¤±è´¥: ${file.name}`, error);
        }
      }
      // 2. åˆæˆæ€»æ—¶é•¿æ”¹ä¸ºè¯­éŸ³æ€»æ—¶é•¿ï¼ŒéŸ³ä¹å¾ªç¯é™ªè¡¬è¯­éŸ³
      const totalDuration = voiceDuration;
      // 3. èƒŒæ™¯éŸ³ä¹å¾ªç¯
      const musicBufferList: { buffer: AudioBuffer; gain: number }[] = [];
      for (const file of musicFiles) {
        try {
          const response = await fetch(file.url);
          const arrayBuffer = await response.arrayBuffer();
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          // éŸ³ä¹æ–‡ä»¶ä¸åŒºåˆ†å•æ–‡ä»¶å¢ç›Šï¼Œè½¨é“çº§ç”±ä¸»å¢ç›ŠèŠ‚ç‚¹ç»Ÿä¸€æ§åˆ¶
          musicBufferList.push({
            buffer: audioBuffer,
            gain: 1
          });
        } catch (error) {
          console.error(`åŠ è½½éŸ³ä¹æ–‡ä»¶å¤±è´¥: ${file.name}`, error);
        }
      }
      if (voiceBufferList.length === 0 && musicBufferList.length === 0) {
        toast.error('æ²¡æœ‰å¯æ’­æ”¾çš„éŸ³é¢‘æ–‡ä»¶');
        return;
      }
      // åˆ›å»ºå¹¶é…ç½®æ¯è½¨é“ä¸»å¢ç›ŠèŠ‚ç‚¹ï¼ˆç”¨äºå®æ—¶è”åŠ¨ï¼‰
      const voiceMasterGain = audioContext.createGain();
      voiceMasterGain.gain.value = (voiceVolume / 100) * (voiceGain / 100) * (voiceMuted ? 0 : 1);
      voiceMasterGain.connect(audioContext.destination);
      voiceMasterGainRef.current = voiceMasterGain;

      const musicMasterGain = audioContext.createGain();
      musicMasterGain.gain.value = (musicVolume / 100) * (musicGain / 100) * (musicMuted ? 0 : 1);
      musicMasterGain.connect(audioContext.destination);
      musicMasterGainRef.current = musicMasterGain;
      // 4. æ’­æ”¾è¯­éŸ³è½¨é“ï¼ˆé¡ºåºæ‹¼æ¥ï¼‰
      let offset = 0;
      voiceBufferList.forEach(({ buffer, gain, duration }) => {
        const source = audioContext.createBufferSource();
        const gainNode = audioContext.createGain();
        source.buffer = buffer;
        // å®æ—¶éŸ³è°ƒæ§åˆ¶ï¼šä½¿ç”¨ playbackRate æ˜ å°„ 50%~200% åˆ° 0.5~2.0
        try {
          source.playbackRate.value = (voicePitch / 100);
        } catch {}
        gainNode.gain.value = gain;
        source.connect(gainNode);
        // æ¥å…¥è¯­éŸ³ä¸»å¢ç›ŠèŠ‚ç‚¹
        gainNode.connect(voiceMasterGainRef.current!);
        source.start(audioContext.currentTime + offset);
        voiceSourcesRef.current.push(source);
        offset += duration;
      });
      // 5. å¾ªç¯æ’­æ”¾èƒŒæ™¯éŸ³ä¹ï¼Œå¡«æ»¡ totalDuration
      if (musicBufferList.length > 0) {
        let musicOffset = 0;
        while (musicOffset < totalDuration) {
          for (const { buffer, gain } of musicBufferList) {
            const source = audioContext.createBufferSource();
            const gainNode = audioContext.createGain();
            source.buffer = buffer;
            gainNode.gain.value = gain;
            source.connect(gainNode);
            // æ¥å…¥éŸ³ä¹ä¸»å¢ç›ŠèŠ‚ç‚¹
            gainNode.connect(musicMasterGainRef.current!);
            const playDuration = Math.min(buffer.duration, totalDuration - musicOffset);
            source.start(audioContext.currentTime + musicOffset);
            // å¦‚æœæœ€åä¸€æ®µä¸è¶³ä¸€é¦–ï¼Œæå‰ stop
            if (playDuration < buffer.duration) {
              source.stop(audioContext.currentTime + musicOffset + playDuration);
            }
            musicSourcesRef.current.push(source);
            musicOffset += playDuration;
            if (musicOffset >= totalDuration) break;
          }
        }
      }
      setIsPlaying(true);
      // æ›´æ–°æ’­æ”¾æ—¶é—´
      const updateTime = () => {
        if (audioContext && startTimeRef.current) {
          const elapsed = audioContext.currentTime - startTimeRef.current;
          setCurrentTime(elapsed);
          
          if (isPlaying) {
            animationFrameRef.current = requestAnimationFrame(updateTime);
          }
        }
      };
      
      updateTime();
      
    } catch (error) {
      console.error('æ’­æ”¾å¤±è´¥:', error);
      toast.error('æ’­æ”¾å¤±è´¥');
    }
  }, [voiceFiles, musicFiles, voiceVolume, musicVolume, voiceGain, musicGain, voiceMuted, musicMuted, voiceFileGains, isPlaying, initAudioContext, stopPlayback]);

  // æ’­æ”¾ä¸­å®æ—¶è”åŠ¨ï¼šæ›´æ–°ä¸»å¢ç›ŠèŠ‚ç‚¹çš„å€¼
  useEffect(() => {
    const ctx = audioContextRef.current;
    const node = voiceMasterGainRef.current;
    if (!ctx || !node) return;
    node.gain.value = (voiceVolume / 100) * (voiceGain / 100) * (voiceMuted ? 0 : 1);
  }, [voiceVolume, voiceGain, voiceMuted]);

  useEffect(() => {
    const ctx = audioContextRef.current;
    const node = musicMasterGainRef.current;
    if (!ctx || !node) return;
    node.gain.value = (musicVolume / 100) * (musicGain / 100) * (musicMuted ? 0 : 1);
  }, [musicVolume, musicGain, musicMuted]);

  // æ’­æ”¾ä¸­å®æ—¶è”åŠ¨ï¼šæ›´æ–°è¯­éŸ³éŸ³è°ƒï¼ˆplaybackRateï¼‰
  useEffect(() => {
    const ctx = audioContextRef.current;
    if (!ctx) return;
    const rate = Math.max(0.5, Math.min(2.0, voicePitch / 100));
    try {
      voiceSourcesRef.current.forEach((src) => {
        // æ›´æ–°å·²åœ¨æ’­æ”¾æˆ–å°šæœªå¼€å§‹çš„ source çš„ playbackRate
        if (src && src.playbackRate) {
          src.playbackRate.value = rate;
        }
      });
    } catch (e) {
      console.warn('æ›´æ–°éŸ³è°ƒå¤±è´¥:', e);
    }
  }, [voicePitch]);

  const pauseAudio = useCallback(() => {
    stopPlayback();
    toast.info('å·²æš‚åœæ’­æ”¾');
  }, [stopPlayback]);

  const normalizeVolume = useCallback(async () => {
    if (voiceFiles.length === 0) {
      toast.error('æ²¡æœ‰è¯­éŸ³æ–‡ä»¶éœ€è¦æ ‡å‡†åŒ–');
      return;
    }
    
    setIsNormalizingVolume(true);
    
    try {
      const audioContext = await initAudioContext();
      const newGains: Record<string, number> = {};
      
      // åˆ†ææ¯ä¸ªè¯­éŸ³æ–‡ä»¶çš„éŸ³é‡
      for (const file of voiceFiles) {
        try {
          const response = await fetch(file.url);
          const arrayBuffer = await response.arrayBuffer();
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          
          // è®¡ç®—RMSéŸ³é‡
          let sum = 0;
          let sampleCount = 0;
          
          for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
            const channelData = audioBuffer.getChannelData(channel);
            for (let i = 0; i < channelData.length; i++) {
              sum += channelData[i] * channelData[i];
              sampleCount++;
            }
          }
          
          const rms = Math.sqrt(sum / sampleCount);
          const targetRMS = 0.1; // ç›®æ ‡RMSå€¼
          const gain = Math.min(targetRMS / rms, 3); // é™åˆ¶æœ€å¤§å¢ç›Šä¸º3å€
          
          newGains[file.id] = Math.round(gain * 100);
          
        } catch (error) {
          console.error(`åˆ†ææ–‡ä»¶éŸ³é‡å¤±è´¥: ${file.name}`, error);
          newGains[file.id] = 100; // é»˜è®¤å¢ç›Š
        }
      }
      
      setVoiceFileGains(newGains);
      toast.success('éŸ³é‡æ ‡å‡†åŒ–å®Œæˆ');
      
    } catch (error) {
      console.error('éŸ³é‡æ ‡å‡†åŒ–å¤±è´¥:', error);
      toast.error('éŸ³é‡æ ‡å‡†åŒ–å¤±è´¥');
    } finally {
      setIsNormalizingVolume(false);
    }
  }, [voiceFiles, initAudioContext]);

  const composeAudio = useCallback(async () => {
    if (voiceFiles.length === 0 && musicFiles.length === 0) {
      toast.error('è¯·å…ˆæ·»åŠ éŸ³é¢‘æ–‡ä»¶');
      return;
    }
    setIsComposing(true);
    try {
      const audioContext = await initAudioContext();
      // 1. åŠ è½½è¯­éŸ³æ–‡ä»¶ï¼Œé¡ºåºæ‹¼æ¥
      let voiceTotalDuration = 0;
      const voiceBufferList: { buffer: AudioBuffer; gain: number; duration: number }[] = [];
      for (const file of voiceFiles) {
        try {
          // Android WebView/Capacitor ä¸Šå¯¹ blob:URL çš„ fetch å¯èƒ½å¤±è´¥ï¼Œä¼˜å…ˆä½¿ç”¨åŸå§‹ File å¯¹è±¡è¯»å–
          const arrayBuffer = file.file
            ? await file.file.arrayBuffer()
            : await (await fetch(file.url)).arrayBuffer();
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          const individualGain = voiceFileGains[file.id] || 100;
          voiceBufferList.push({
            buffer: audioBuffer,
            gain: (voiceVolume / 100) * (voiceGain / 100) * (individualGain / 100) * (voiceMuted ? 0 : 1),
            duration: audioBuffer.duration
          });
          voiceTotalDuration += audioBuffer.duration;
        } catch (error) {
          console.error(`åŠ è½½è¯­éŸ³æ–‡ä»¶å¤±è´¥: ${file.name}`, error);
        }
      }
      // Android ç¯å¢ƒä¸‹å¦‚æœæ²¡æœ‰è¯­éŸ³æ–‡ä»¶è€Œåªæœ‰éŸ³ä¹ï¼Œæ€»æ—¶é•¿ä¸º0ä¼šå¯¼è‡´ç¦»çº¿æ¸²æŸ“æŠ¥é”™ï¼Œè¿™é‡Œç›´æ¥æç¤ºå¹¶ä¸­æ­¢
      if (voiceBufferList.length === 0) {
        toast.error('åˆæˆéœ€è¦è‡³å°‘ä¸€ä¸ªè¯­éŸ³æ–‡ä»¶ï¼ˆä»…æœ‰éŸ³ä¹ä¼šå¯¼è‡´å¤±è´¥ï¼‰');
        setIsComposing(false);
        return;
      }
      // 2. åˆæˆæ€»æ—¶é•¿æ”¹ä¸ºè¯­éŸ³æ€»æ—¶é•¿ï¼ŒéŸ³ä¹å¾ªç¯é™ªè¡¬è¯­éŸ³
      const totalDuration = voiceTotalDuration;
      if (!totalDuration || totalDuration <= 0) {
        toast.error('åˆæˆæ—¶é•¿ä¸º0ï¼Œè¯·æ£€æŸ¥è¯­éŸ³æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ');
        setIsComposing(false);
        return;
      }
      // 3. åŠ è½½èƒŒæ™¯éŸ³ä¹æ–‡ä»¶
      const musicBufferList: { buffer: AudioBuffer; gain: number }[] = [];
      for (const file of musicFiles) {
        try {
          const arrayBuffer = file.file
            ? await file.file.arrayBuffer()
            : await (await fetch(file.url)).arrayBuffer();
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          musicBufferList.push({
            buffer: audioBuffer,
            gain: (musicVolume / 100) * (musicGain / 100) * (musicMuted ? 0 : 1)
          });
        } catch (error) {
          console.error(`åŠ è½½éŸ³ä¹æ–‡ä»¶å¤±è´¥: ${file.name}`, error);
        }
      }
      if (voiceBufferList.length === 0 && musicBufferList.length === 0) {
        toast.error('æ²¡æœ‰å¯åˆæˆçš„éŸ³é¢‘æ–‡ä»¶');
        return;
      }
      // 4. åˆ›å»ºç¦»çº¿éŸ³é¢‘ä¸Šä¸‹æ–‡ï¼Œæ—¶é•¿ä¸º totalDuration
      if (typeof OfflineAudioContext === 'undefined') {
        toast.error('å½“å‰ç¯å¢ƒä¸æ”¯æŒç¦»çº¿åˆæˆï¼ˆOfflineAudioContextï¼‰ã€‚è¯·æ›´æ–°ç³»ç»ŸWebViewæˆ–ä½¿ç”¨æµè§ˆå™¨');
        setIsComposing(false);
        return;
      }
      const sampleRate = audioContext.sampleRate;
      const length = Math.ceil(totalDuration * sampleRate);
      const offlineContext = new OfflineAudioContext(2, length, sampleRate);
      // 5. é¡ºåºæ‹¼æ¥è¯­éŸ³è½¨é“
      let offset = 0;
      for (const { buffer, gain, duration } of voiceBufferList) {
        const source = offlineContext.createBufferSource();
        const gainNode = offlineContext.createGain();
        source.buffer = buffer;
        gainNode.gain.value = gain;
        source.connect(gainNode);
        gainNode.connect(offlineContext.destination);
        source.start(offset);
        offset += duration;
      }
      // 6. å¾ªç¯å¡«å……èƒŒæ™¯éŸ³ä¹
      if (musicBufferList.length > 0) {
        let musicOffset = 0;
        while (musicOffset < totalDuration) {
          for (const { buffer, gain } of musicBufferList) {
            const source = offlineContext.createBufferSource();
            const gainNode = offlineContext.createGain();
            source.buffer = buffer;
            gainNode.gain.value = gain;
            source.connect(gainNode);
            gainNode.connect(offlineContext.destination);
            const playDuration = Math.min(buffer.duration, totalDuration - musicOffset);
            source.start(musicOffset);
            // å¦‚æœæœ€åä¸€æ®µä¸è¶³ä¸€é¦–ï¼Œæå‰ stop
            if (playDuration < buffer.duration) {
              source.stop(musicOffset + playDuration);
            }
            musicOffset += playDuration;
            if (musicOffset >= totalDuration) break;
          }
        }
      }
      // 7. æ¸²æŸ“éŸ³é¢‘
      let renderedBuffer: AudioBuffer;
      try {
        renderedBuffer = await offlineContext.startRendering();
      } catch (renderErr: any) {
        console.error('ç¦»çº¿æ¸²æŸ“å¤±è´¥:', renderErr);
        toast.error(`éŸ³é¢‘åˆæˆå¤±è´¥ï¼ˆæ¸²æŸ“é”™è¯¯ï¼‰ï¼š${renderErr?.message || 'æœªçŸ¥åŸå› '}`);
        setIsComposing(false);
        return;
      }
      
      // è½¬æ¢ä¸ºWAVæ ¼å¼
      const wavBuffer = audioBufferToWav(renderedBuffer);
      const blob = new Blob([wavBuffer], { type: 'audio/wav' });
      
      // æ¸…ç†æ—§çš„åˆæˆéŸ³é¢‘URL
      if (composedAudioUrl) {
        removeUrlRef(composedAudioUrl);
      }
      
      // åˆ›å»ºæ–°çš„URL
      const url = URL.createObjectURL(blob);
      addUrlRef(url);
      setComposedAudioUrl(url);
      
      toast.success('éŸ³é¢‘åˆæˆå®Œæˆï¼');
      
    } catch (error: any) {
      console.error('éŸ³é¢‘åˆæˆå¤±è´¥:', error);
      // æä¾›æ›´æ˜ç¡®çš„é”™è¯¯æç¤ºï¼Œä¾¿äº Android ç¯å¢ƒå®šä½é—®é¢˜
      const msg = typeof error?.message === 'string' ? error.message : 'æœªçŸ¥åŸå› ';
      toast.error(`éŸ³é¢‘åˆæˆå¤±è´¥ï¼š${msg}`);
    } finally {
      setIsComposing(false);
    }
  }, [voiceFiles, musicFiles, voiceVolume, musicVolume, voiceGain, musicGain, voiceMuted, musicMuted, voiceFileGains, composedAudioUrl, initAudioContext, addUrlRef, removeUrlRef]);

  const downloadComposedAudio = useCallback(() => {
    if (!composedAudioUrl) {
      toast.error('æ²¡æœ‰å¯ä¸‹è½½çš„åˆæˆéŸ³é¢‘');
      return;
    }
    
    const link = document.createElement('a');
    link.href = composedAudioUrl;
    link.download = `åˆæˆéŸ³é¢‘_${new Date().toISOString().slice(0, 19).replace(/:/g, '-')}.wav`;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    
    toast.success('å¼€å§‹ä¸‹è½½åˆæˆéŸ³é¢‘');
  }, [composedAudioUrl]);

  return {
    // çŠ¶æ€
    voiceFiles,
    musicFiles,
    isPlaying,
    currentTime,
    voiceVolume,
    musicVolume,
    voiceMuted,
    musicMuted,
    composedAudioUrl,
    isComposing,
    voiceGain,
    musicGain,
    voicePitch,
    voiceFileGains,
    isNormalizingVolume,
    
    // æ§åˆ¶å‡½æ•°
    setVoiceVolume,
    setMusicVolume,
    setVoiceMuted,
    setMusicMuted,
    setVoiceGain,
    setMusicGain,
    setVoicePitch,
    setVoiceFileGains,
    
    // æ“ä½œå‡½æ•°
    handleFilesUpload,
    removeFile,
    clearAllFiles,
    playAudio,
    pauseAudio,
    normalizeVolume,
    composeAudio,
    downloadComposedAudio,
    reorderFiles,
    
    // æ–°å¢çš„URLç®¡ç†å’Œæ¢å¤åŠŸèƒ½
    validateBlobUrl,
    recoverFailedUrl,
    checkAndRecoverAudioFiles,
    
    // è°ƒè¯•å‡½æ•°
    logActiveUrls
  };
};

// è¾…åŠ©å‡½æ•°ï¼šå°†AudioBufferè½¬æ¢ä¸ºWAVæ ¼å¼
function audioBufferToWav(buffer: AudioBuffer): ArrayBuffer {
  const length = buffer.length;
  const numberOfChannels = buffer.numberOfChannels;
  const sampleRate = buffer.sampleRate;
  const arrayBuffer = new ArrayBuffer(44 + length * numberOfChannels * 2);
  const view = new DataView(arrayBuffer);
  
  // WAVæ–‡ä»¶å¤´
  const writeString = (offset: number, string: string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  };
  
  writeString(0, 'RIFF');
  view.setUint32(4, 36 + length * numberOfChannels * 2, true);
  writeString(8, 'WAVE');
  writeString(12, 'fmt ');
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true);
  view.setUint16(22, numberOfChannels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * numberOfChannels * 2, true);
  view.setUint16(32, numberOfChannels * 2, true);
  view.setUint16(34, 16, true);
  writeString(36, 'data');
  view.setUint32(40, length * numberOfChannels * 2, true);
  
  // éŸ³é¢‘æ•°æ®
  let offset = 44;
  for (let i = 0; i < length; i++) {
    for (let channel = 0; channel < numberOfChannels; channel++) {
      const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]));
      view.setInt16(offset, sample * 0x7FFF, true);
      offset += 2;
    }
  }
  
  return arrayBuffer;
}